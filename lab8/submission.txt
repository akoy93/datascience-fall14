===================== Storm: WordCountTopology.java

/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.umd.assignment;

import backtype.storm.Config;
import backtype.storm.LocalCluster;
import backtype.storm.StormSubmitter;
import backtype.storm.task.ShellBolt;
import backtype.storm.topology.BasicOutputCollector;
import backtype.storm.topology.IRichBolt;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.TopologyBuilder;
import backtype.storm.topology.base.BaseBasicBolt;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Tuple;
import backtype.storm.tuple.Values;

import org.umd.assignment.spout.RandomSentenceSpout;
import org.umd.assignment.spout.TwitterSampleSpout;

import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.PriorityQueue;

/**
 * This topology demonstrates Storm's stream groupings and multilang capabilities.
 */
public class WordCountTopology {
  public static class SplitSentence extends ShellBolt implements IRichBolt {

    public SplitSentence() {
      super("python", "splitsentence.py");
    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
      declarer.declare(new Fields("word"));
    }

    @Override
    public Map<String, Object> getComponentConfiguration() {
      return null;
    }
  }

  public static class WordCount extends BaseBasicBolt {
    Map<String, Integer> counts = new HashMap<String, Integer>();
  HashSet<String> stopWords = new HashSet<String>();  

  public WordCount() {
    stopWords.add("a");
    stopWords.add("about");
    stopWords.add("above");
    stopWords.add("across");
    stopWords.add("after");
    stopWords.add("again");
    stopWords.add("against");
    stopWords.add("all");
    stopWords.add("almost");
    stopWords.add("alone");
    stopWords.add("along");
    stopWords.add("already");
    stopWords.add("also");
    stopWords.add("although");
    stopWords.add("always");
    stopWords.add("among");
    stopWords.add("an");
    stopWords.add("and");
    stopWords.add("another");
    stopWords.add("any");
    stopWords.add("anybody");
    stopWords.add("anyone");
    stopWords.add("anything");
    stopWords.add("anywhere");
    stopWords.add("are");
    stopWords.add("area");
    stopWords.add("areas");
    stopWords.add("around");
  }

    @Override
    public void execute(Tuple tuple, BasicOutputCollector collector) {
      
    // ----------------- Task 2 ---------------------------------
    //
    //
    //  Modify this code to exclude stop-words from counting.
    //  Stopword list is provided in the lab folder. 
    //
    //
    // ---------------------------------------------------------


    String word = tuple.getString(0);
    if (!stopWords.contains(word.toLowerCase())) {
      Integer count = counts.get(word);
      if (count == null)
        count = 0;
      count++;
      counts.put(word, count);
      collector.emit(new Values(word, count));  
    }
    }

  @Override
  public void cleanup()
  {
    // ------------------------  Task 3 ---------------------------------------
    //
    //
    //  This function gets called when the Stream processing finishes.
    //  MODIFY this function to print the most frequent words that co-occur 
    //  with Obama [The TwitterSimpleSpout already gives you Tweets that contain
    //  the word obama].
    //
    //  Since multiple threads will be doing the same cleanup operation, writing the
    //  output to a file might not work as desired. One way to do this would be
    //  print the output (using System.out.println) and do a grep/awk/sed on that.
    //  For a simple example see inside the runStorm.sh.
    //
    //--------------------------------------------------------------------------

    System.out.println("Top 10 ------------------------------------");

    PriorityQueue<String> q = new PriorityQueue<String>(11, new Comparator<String>() {

      @Override
      public int compare(String a, String b) {
        return counts.get(b) - counts.get(a);
      }

    });

    for (String word : counts.keySet()) {
      q.add(word);
    }

    for (int i = 0; i < 10; i++) {
      String word = q.poll();
      System.out.println(word + " " + counts.get(word));
    }
  }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
      declarer.declare(new Fields("word", "count"));
    }
  }

  public static void main(String[] args) throws Exception {

    TopologyBuilder builder = new TopologyBuilder();

  // ---------------------------- Task 1 -------------------------------------
  //
  //    You need to use TwitterSampleSpout() for the assignemt. But, it won't work
  //    unless you set up the access token correctly in the TwitterSampleSpout.java
  //
  //    RandomSentenceSpout() simply spits out a random sentence. 
  //
  //--------------------------------------------------------------------------

  // Setting up a spout
    // builder.setSpout("spout", new RandomSentenceSpout(), 3); //builder.setSpout("spout", new TwitterSampleSpout(), 3);
  builder.setSpout("spout", new TwitterSampleSpout(), 10);

  // Setting up bolts
    builder.setBolt("split", new SplitSentence(), 10).shuffleGrouping("spout");
    builder.setBolt("count", new WordCount(), 10).fieldsGrouping("split", new Fields("word"));

    Config conf = new Config();
    conf.setDebug(true);


    if (args != null && args.length > 0) {
      conf.setNumWorkers(10);

      StormSubmitter.submitTopologyWithProgressBar(args[0], conf, builder.createTopology());
    }
    else {
      conf.setMaxTaskParallelism(10);

      LocalCluster cluster = new LocalCluster();
      cluster.submitTopology("word-count", conf, builder.createTopology());

    // --------------------------- Task 4 ---------------------------------
    //
    //  The sleep time simply indicates for how long you want to keep your
    //  system up and running. 10000 (miliseconds) here means 10 seconds.
    //  
    //
    // ----------------------------------------------------------------------

      Thread.sleep(600000);

      cluster.shutdown(); // blot "cleanup" function is called when cluster is shutdown (only works in local mode)
    }
  }
}

===================== Storm: TwitterSampleSpout.java

/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


//package org.umd.assignment.spout;

package org.umd.assignment.spout;

import java.util.Map;
import java.util.concurrent.LinkedBlockingQueue;

import twitter4j.FilterQuery;
import twitter4j.StallWarning;
import twitter4j.Status;
import twitter4j.StatusDeletionNotice;
import twitter4j.StatusListener;
import twitter4j.TwitterStream;
import twitter4j.TwitterStreamFactory;
import twitter4j.auth.AccessToken;
import twitter4j.conf.ConfigurationBuilder;

import backtype.storm.Config;
import backtype.storm.spout.SpoutOutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichSpout;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Values;
import backtype.storm.utils.Utils;

@SuppressWarnings("serial")
public class TwitterSampleSpout extends BaseRichSpout {

  SpoutOutputCollector _collector;
  LinkedBlockingQueue<String> queue = null;
  TwitterStream _twitterStream;
  String consumerKey;
  String consumerSecret;
  String accessToken;
  String accessTokenSecret;
  String[] keyWords;
  
  public TwitterSampleSpout(String consumerKey, String consumerSecret,
      String accessToken, String accessTokenSecret, String[] keyWords) {
    this.consumerKey = consumerKey;
    this.consumerSecret = consumerSecret;
    this.accessToken = accessToken;
    this.accessTokenSecret = accessTokenSecret;
    this.keyWords = keyWords;
  }


  //----------------------- Task 0 -----------------------------------------
  //
  //  Use the following link (for visual help) to create a Twitter App for yourselves. In summary,
  //  the steps are:
  //        (a) Go to apps.twitter.com
  //        (b) Create an App [Put any website as an URL]
  //        (c) Go to "keys and Access Token tab"
  //        (d) Create you access token
  //        (e) Copy over the ConsumerKey, consumerSecret, accesstoken, and accessTokenSecret
  //        in the TwitterSampleSpout()
  //
  //  https://dev.twitter.com/oauth/overview/application-owner-access-tokens
  //  
  //
  //
  //------------------------------------------------------------------------

  public TwitterSampleSpout() {   
    this.consumerKey = "WFzhpMi3lgKvVRlYRzKG7YQGa";
    this.consumerSecret = "u8jhR4ill89JtxThiCsJtzjzPHH7Fk14vkcv3jFvu3BnMOSS0I";
    this.accessToken = "181390106-zkxuSCOrU8amPZfMO7iZUXBjzBgwAThzoVdM8uVN";
    this.accessTokenSecret = "APPNJ4QzHaqfhXzgz90O3DeLpGY19fmZoC1nch82kH5Z1";
    this.keyWords = new String[1];
    this.keyWords[0] = "obama"; /* Filters All Tweets with word Obama */
  }

  @Override
  public void open(Map conf, TopologyContext context,
      SpoutOutputCollector collector) {
    queue = new LinkedBlockingQueue<String>(1000);
    _collector = collector;

    StatusListener listener = new StatusListener() {

      @Override
      public void onStatus(Status status) {
      
        queue.offer(status.getText());
      }

      @Override
      public void onDeletionNotice(StatusDeletionNotice sdn) {
      }

      @Override
      public void onTrackLimitationNotice(int i) {
      }

      @Override
      public void onScrubGeo(long l, long l1) {
      }

      @Override
      public void onException(Exception ex) {
      }

      @Override
      public void onStallWarning(StallWarning arg0) {
        // TODO Auto-generated method stub

      }

    };

    _twitterStream = new TwitterStreamFactory(
        new ConfigurationBuilder().setJSONStoreEnabled(true).build())
        .getInstance();

    _twitterStream.addListener(listener);
    _twitterStream.setOAuthConsumer(consumerKey, consumerSecret);
    AccessToken token = new AccessToken(accessToken, accessTokenSecret);
    _twitterStream.setOAuthAccessToken(token);
    
    if (keyWords.length == 0) {

      _twitterStream.sample();
    }

    else {

      FilterQuery query = new FilterQuery().track(keyWords);
      _twitterStream.filter(query);
    }

  }

  @Override
  public void nextTuple() {
    String ret = queue.poll();
    if (ret == null) {
      Utils.sleep(50);
    } else {
         
      _collector.emit(new Values(ret));

    }
  }

  @Override
  public void close() {
    _twitterStream.shutdown();
  }

  @Override
  public Map<String, Object> getComponentConfiguration() {
    Config ret = new Config();
    ret.setMaxTaskParallelism(1);
    return ret;
  }

  @Override
  public void ack(Object id) {
  }

  @Override
  public void fail(Object id) {
  }

  @Override
  public void declareOutputFields(OutputFieldsDeclarer declarer) {
    declarer.declare(new Fields("tweet"));
  }

}

===================== Storm: Execution Output for a Sample Run

Top 10 ------------------------------------
Michael 93
Vilsack 45
bond 45
professional 41
by 39
you 38
Guantanamo 25
The 23
proving 21
@Reverend_Scott: 20
Top 10 ------------------------------------
Obama 511
is 117
 106
have 54
Barack 46
Washington: 41
agricultur... 40
via 36
GOP 36
will 30
Top 10 ------------------------------------
the 224
had 95
@TisaCuh: 89
on 61
forge 45
time 30
Fox 30
I'm 28
like 23
de 20
Top 10 ------------------------------------
Obama's 117
they 34
Obama: 30
Why 26
one 22
set 21
obama 20
@washingtonpost: 20
IMMA 20
How 18
Top 10 ------------------------------------
of 142
say 98
at 58
I 46
that 22
Wave 21
undocumented 21
News 20
Sharpton 18
authority, 15
Top 10 ------------------------------------
President 57
personal 41
with 35
just 30
immigration 26
asks 25
his 24
who 24
over 23
patron 23
Top 10 ------------------------------------
- 169
in 125
See 91
#Obama 41
For 25
Daughters 25
girls 25
people, 22
hard 21
DC 20
Top 10 ------------------------------------
RT 529
what 102
has 72
Please 24
measure 21
Joe.

Biden: 19
from 15
#Ferguson 15
Ashton

Everybody's 14
can 12
Top 10 ------------------------------------
to 245
for 160
sp 89
special 45
small 45
shops 31
many 29
meet 22
immigrants 21
#tcot 21
Top 10 ------------------------------------
http://t.co/xWzzXh66JT 89
Jordan: 89
Obama, 60
admiration 41
& 38
business 23
Congress 23
(IBD) 16
'Social 16
answer.. 15

===================== Spark: Assignment.java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
import scala.Tuple2;
import com.google.common.collect.Lists;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;

import java.util.regex.Pattern;

public final class Assignment {
    private static final Pattern SPACE = Pattern.compile(" ");

    public static void main(String[] args) {

        // Create the context with a 10 second batch size
        SparkConf sparkConf = new SparkConf().setAppName("Assignment");
        JavaStreamingContext ssc = new JavaStreamingContext(sparkConf,  new Duration(10000));

        // Create a JavaReceiverInputDStream on target ip:port and count the
        // words in input stream of \n delimited text (eg. generated by 'nc')
        // Note that no duplication in storage level only for running locally.
        // Replication necessary in distributed scenario for fault tolerance.
        JavaReceiverInputDStream<String> lines = ssc.socketTextStream(
                "localhost", Integer.parseInt("9999"), StorageLevels.MEMORY_AND_DISK_SER);

        JavaDStream<String> words = lines.flatMap(new FlatMapFunction<String, String>() {
                @Override
                public Iterable<String> call(String x) {
                return Lists.newArrayList(SPACE.split(x));
                }
                });

        JavaPairDStream<String, Integer> wordCounts = words.mapToPair(
                new PairFunction<String, String, Integer>() {
                @Override
                public Tuple2<String, Integer> call(String s) {
                return new Tuple2<String, Integer>(s.toLowerCase(), 1);
                }
                });

        Function2<Integer, Integer, Integer> reduceFunc = new Function2<Integer, Integer, Integer>() {
            @Override
            public Integer call(Integer i1, Integer i2) throws Exception {
                return i1 + i2;
            }
        };

        JavaPairDStream<String, Integer> windowedWordCounts = 
            wordCounts.reduceByKeyAndWindow(reduceFunc, new Duration(30000), new Duration(10000)).
            filter(new Function<Tuple2<String, Integer>, Boolean>() {
                public Boolean call(Tuple2<String, Integer> wordCount) {
                    return wordCount._1.equals("#obama");
                }
            });

        windowedWordCounts.print();

        ssc.start();

        ssc.awaitTermination();
    }
}

===================== Spark: Execution Output for a Sample Run

-------------------------------------------
Time: 1417332740000 ms
-------------------------------------------

-------------------------------------------
Time: 1417332750000 ms
-------------------------------------------
(#obama,16)

-------------------------------------------
Time: 1417332760000 ms
-------------------------------------------
(#obama,31)

-------------------------------------------
Time: 1417332770000 ms
-------------------------------------------
(#obama,48)

-------------------------------------------
Time: 1417332780000 ms
-------------------------------------------
(#obama,56)

-------------------------------------------
Time: 1417332790000 ms
-------------------------------------------
(#obama,41)

-------------------------------------------
Time: 1417332800000 ms
-------------------------------------------
(#obama,24)

-------------------------------------------
Time: 1417332810000 ms
-------------------------------------------

-------------------------------------------
Time: 1417332820000 ms
-------------------------------------------




